{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Dataset/Train'\n",
    "valid_path = 'Dataset/Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 35s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    "mobilnet = InceptionV3(input_shape=IMAGE_SIZE + [3],weights='imagenet', include_top=False)\n",
    "\n",
    "#mobilnet = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in mobilnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # useful for getting number of output classes\n",
    "folders = glob('Dataset/Train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset/Train\\\\Parasite', 'Dataset/Train\\\\Uninfected']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=mobilnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 51200)        0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            102402      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,905,186\n",
      "Trainable params: 102,402\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               25088500  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 25,100,046\n",
      "Trainable params: 25,100,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Create Model from scratch using CNN\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation =\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x62305a8488>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('Dataset/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 21s 2s/step - loss: 1.2673 - accuracy: 0.5168 - val_loss: 0.6489 - val_accuracy: 0.6791\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 13s 987ms/step - loss: 0.6793 - accuracy: 0.5938 - val_loss: 0.7149 - val_accuracy: 0.3582\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.6579 - accuracy: 0.5913 - val_loss: 0.8377 - val_accuracy: 0.3507\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.5996 - accuracy: 0.6683 - val_loss: 0.7888 - val_accuracy: 0.3582\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5621 - accuracy: 0.6683 - val_loss: 0.9890 - val_accuracy: 0.3731\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5027 - accuracy: 0.7332 - val_loss: 0.8484 - val_accuracy: 0.3507\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.4568 - accuracy: 0.7716 - val_loss: 1.3521 - val_accuracy: 0.3731\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.4456 - accuracy: 0.7788 - val_loss: 0.8596 - val_accuracy: 0.4179\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.3669 - accuracy: 0.8101 - val_loss: 0.6709 - val_accuracy: 0.6119\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.3557 - accuracy: 0.8413 - val_loss: 0.9304 - val_accuracy: 0.5746\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.3352 - accuracy: 0.8654 - val_loss: 0.6082 - val_accuracy: 0.6642\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.2554 - accuracy: 0.8918 - val_loss: 0.6939 - val_accuracy: 0.6418\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 16s 1s/step - loss: 0.2959 - accuracy: 0.8798 - val_loss: 0.4077 - val_accuracy: 0.8358\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.2428 - accuracy: 0.9231 - val_loss: 0.4918 - val_accuracy: 0.7761\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1858 - accuracy: 0.9495 - val_loss: 0.3337 - val_accuracy: 0.8358\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1439 - accuracy: 0.9375 - val_loss: 0.3239 - val_accuracy: 0.8657\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1328 - accuracy: 0.9543 - val_loss: 0.2594 - val_accuracy: 0.8731\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 13s 962ms/step - loss: 0.1144 - accuracy: 0.9688 - val_loss: 0.2520 - val_accuracy: 0.8881\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 13s 982ms/step - loss: 0.0874 - accuracy: 0.9712 - val_loss: 0.4593 - val_accuracy: 0.8284\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1000 - accuracy: 0.9663 - val_loss: 0.2255 - val_accuracy: 0.9030\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0895 - accuracy: 0.9663 - val_loss: 0.2580 - val_accuracy: 0.8881\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1129 - accuracy: 0.9591 - val_loss: 0.2468 - val_accuracy: 0.9179\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1319 - accuracy: 0.9591 - val_loss: 0.2117 - val_accuracy: 0.9104\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.2521 - val_accuracy: 0.8881\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0685 - accuracy: 0.9784 - val_loss: 0.3077 - val_accuracy: 0.8806\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0690 - accuracy: 0.9808 - val_loss: 0.1910 - val_accuracy: 0.9179\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0427 - accuracy: 0.9880 - val_loss: 0.2914 - val_accuracy: 0.8955\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 0.3163 - val_accuracy: 0.8881\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0462 - accuracy: 0.9904 - val_loss: 0.2724 - val_accuracy: 0.9030\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0389 - accuracy: 0.9904 - val_loss: 0.2326 - val_accuracy: 0.9328\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.1958 - val_accuracy: 0.9328\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.2299 - val_accuracy: 0.9254\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0361 - accuracy: 0.9880 - val_loss: 0.1714 - val_accuracy: 0.9328\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0415 - accuracy: 0.9952 - val_loss: 0.2425 - val_accuracy: 0.9254\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0288 - accuracy: 0.9880 - val_loss: 0.1189 - val_accuracy: 0.9478\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0796 - accuracy: 0.9808 - val_loss: 0.3237 - val_accuracy: 0.8731\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0527 - accuracy: 0.9808 - val_loss: 0.2635 - val_accuracy: 0.8881\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0638 - accuracy: 0.9736 - val_loss: 0.3064 - val_accuracy: 0.8955\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0828 - accuracy: 0.9832 - val_loss: 0.3142 - val_accuracy: 0.8806\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0648 - accuracy: 0.9832 - val_loss: 0.2077 - val_accuracy: 0.9254\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0661 - accuracy: 0.9760 - val_loss: 0.2837 - val_accuracy: 0.8955\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.1718 - val_accuracy: 0.9478\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0192 - accuracy: 0.9976 - val_loss: 0.2923 - val_accuracy: 0.9328\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.2308 - val_accuracy: 0.9328\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 0.1691 - val_accuracy: 0.9478\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.6952 - val_accuracy: 0.8507\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0577 - accuracy: 0.9832 - val_loss: 0.1721 - val_accuracy: 0.9403\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 13s 984ms/step - loss: 0.0397 - accuracy: 0.9904 - val_loss: 0.2636 - val_accuracy: 0.9104\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0185 - accuracy: 0.9976 - val_loss: 0.2567 - val_accuracy: 0.9478\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.4150 - val_accuracy: 0.8955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bb6bf5bcc936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# plot the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.29416543e-01, 6.70583427e-01],\n",
       "       [9.95525658e-01, 4.47429763e-03],\n",
       "       [6.73307717e-01, 3.26692283e-01],\n",
       "       [2.50407457e-01, 7.49592543e-01],\n",
       "       [8.05086315e-01, 1.94913730e-01],\n",
       "       [9.83192682e-01, 1.68073103e-02],\n",
       "       [3.27049881e-01, 6.72950089e-01],\n",
       "       [9.40743625e-01, 5.92564195e-02],\n",
       "       [6.55883491e-01, 3.44116569e-01],\n",
       "       [7.58942544e-01, 2.41057441e-01],\n",
       "       [1.15816243e-01, 8.84183705e-01],\n",
       "       [2.08479792e-01, 7.91520238e-01],\n",
       "       [9.77544665e-01, 2.24552937e-02],\n",
       "       [8.02779272e-02, 9.19722140e-01],\n",
       "       [2.22165838e-01, 7.77834117e-01],\n",
       "       [1.77248389e-01, 8.22751641e-01],\n",
       "       [4.15821135e-01, 5.84178925e-01],\n",
       "       [9.99977350e-01, 2.26920802e-05],\n",
       "       [1.74954310e-01, 8.25045764e-01],\n",
       "       [1.93584010e-01, 8.06416035e-01],\n",
       "       [8.48712683e-01, 1.51287377e-01],\n",
       "       [9.74758148e-01, 2.52418090e-02],\n",
       "       [9.99992490e-01, 7.49614537e-06],\n",
       "       [3.54146659e-01, 6.45853341e-01],\n",
       "       [4.21301156e-01, 5.78698874e-01],\n",
       "       [9.88253713e-01, 1.17462389e-02],\n",
       "       [9.96264040e-01, 3.73595254e-03],\n",
       "       [6.78568304e-01, 3.21431696e-01],\n",
       "       [9.92771924e-01, 7.22810905e-03],\n",
       "       [2.55523622e-01, 7.44476378e-01],\n",
       "       [9.92279649e-01, 7.72041176e-03],\n",
       "       [9.95776892e-01, 4.22303658e-03],\n",
       "       [1.76977932e-01, 8.23022068e-01],\n",
       "       [9.73526001e-01, 2.64739320e-02],\n",
       "       [2.70457804e-01, 7.29542255e-01],\n",
       "       [8.17880034e-01, 1.82119966e-01],\n",
       "       [8.34860057e-02, 9.16513979e-01],\n",
       "       [9.99870658e-01, 1.29271008e-04],\n",
       "       [7.43492246e-02, 9.25650716e-01],\n",
       "       [6.54268116e-02, 9.34573174e-01],\n",
       "       [6.63791150e-02, 9.33620870e-01],\n",
       "       [4.39406991e-01, 5.60593069e-01],\n",
       "       [9.99294162e-01, 7.05859857e-04],\n",
       "       [4.87737954e-01, 5.12262046e-01],\n",
       "       [9.93158042e-01, 6.84201205e-03],\n",
       "       [8.43518257e-01, 1.56481743e-01],\n",
       "       [1.26347318e-01, 8.73652697e-01],\n",
       "       [1.14622921e-01, 8.85377109e-01],\n",
       "       [6.53875470e-01, 3.46124560e-01],\n",
       "       [9.99788225e-01, 2.11805978e-04],\n",
       "       [1.30622134e-01, 8.69377851e-01],\n",
       "       [7.71351457e-01, 2.28648558e-01],\n",
       "       [9.87406909e-01, 1.25931529e-02],\n",
       "       [5.71612060e-01, 4.28387970e-01],\n",
       "       [9.89320159e-01, 1.06798336e-02],\n",
       "       [9.11737919e-01, 8.82620364e-02],\n",
       "       [9.97617781e-01, 2.38217134e-03],\n",
       "       [9.97327924e-01, 2.67208461e-03],\n",
       "       [1.87402263e-01, 8.12597752e-01],\n",
       "       [9.99943972e-01, 5.60346634e-05],\n",
       "       [7.84140646e-01, 2.15859339e-01],\n",
       "       [2.03387141e-01, 7.96612859e-01],\n",
       "       [1.44742578e-01, 8.55257452e-01],\n",
       "       [9.98010695e-01, 1.98936230e-03],\n",
       "       [3.27054173e-01, 6.72945797e-01],\n",
       "       [2.03490049e-01, 7.96509862e-01],\n",
       "       [6.77069724e-01, 3.22930336e-01],\n",
       "       [9.98355806e-01, 1.64411590e-03],\n",
       "       [9.99343216e-01, 6.56756107e-04],\n",
       "       [9.49380219e-01, 5.06197289e-02],\n",
       "       [2.10850075e-01, 7.89149880e-01],\n",
       "       [2.35863447e-01, 7.64136553e-01],\n",
       "       [4.97254342e-01, 5.02745688e-01],\n",
       "       [9.78885829e-01, 2.11142078e-02],\n",
       "       [2.24140927e-01, 7.75859058e-01],\n",
       "       [1.08926237e-01, 8.91073823e-01],\n",
       "       [9.94520485e-01, 5.47953416e-03],\n",
       "       [9.11949649e-02, 9.08805072e-01],\n",
       "       [1.28286749e-01, 8.71713221e-01],\n",
       "       [3.59295130e-01, 6.40704870e-01],\n",
       "       [9.17644203e-01, 8.23558196e-02],\n",
       "       [9.77849960e-01, 2.21500900e-02],\n",
       "       [5.78075290e-01, 4.21924740e-01],\n",
       "       [1.62909448e-01, 8.37090492e-01],\n",
       "       [9.72945452e-01, 2.70545632e-02],\n",
       "       [8.98051083e-01, 1.01948969e-01],\n",
       "       [5.15213788e-01, 4.84786212e-01],\n",
       "       [1.99757397e-01, 8.00242603e-01],\n",
       "       [9.20566320e-01, 7.94336647e-02],\n",
       "       [1.42323107e-01, 8.57676864e-01],\n",
       "       [6.25370622e-01, 3.74629408e-01],\n",
       "       [2.72417694e-01, 7.27582335e-01],\n",
       "       [1.49873406e-01, 8.50126565e-01],\n",
       "       [9.67939138e-01, 3.20608094e-02],\n",
       "       [1.66356310e-01, 8.33643675e-01],\n",
       "       [2.28961334e-01, 7.71038711e-01],\n",
       "       [1.48915932e-01, 8.51084054e-01],\n",
       "       [6.62511170e-01, 3.37488800e-01],\n",
       "       [1.38719141e-01, 8.61280799e-01],\n",
       "       [9.97879028e-01, 2.12099124e-03],\n",
       "       [9.99918818e-01, 8.11756763e-05],\n",
       "       [8.59168470e-01, 1.40831530e-01],\n",
       "       [9.93039548e-01, 6.96044276e-03],\n",
       "       [9.77225721e-01, 2.27743275e-02],\n",
       "       [1.66585639e-01, 8.33414376e-01],\n",
       "       [3.25097919e-01, 6.74902081e-01],\n",
       "       [8.53293017e-02, 9.14670706e-01],\n",
       "       [9.99404311e-01, 5.95748541e-04],\n",
       "       [9.06740308e-01, 9.32597518e-02],\n",
       "       [7.06508279e-01, 2.93491721e-01],\n",
       "       [9.24743593e-01, 7.52564445e-02],\n",
       "       [9.05589685e-02, 9.09441054e-01],\n",
       "       [8.60387504e-01, 1.39612496e-01],\n",
       "       [8.78447220e-02, 9.12155330e-01],\n",
       "       [9.95086133e-01, 4.91380552e-03],\n",
       "       [2.90698707e-01, 7.09301233e-01],\n",
       "       [3.72008055e-01, 6.27991974e-01],\n",
       "       [2.47528359e-01, 7.52471626e-01],\n",
       "       [1.06535621e-01, 8.93464327e-01],\n",
       "       [2.08932742e-01, 7.91067302e-01],\n",
       "       [9.92426276e-01, 7.57371401e-03],\n",
       "       [5.72016835e-01, 4.27983165e-01],\n",
       "       [9.87441421e-01, 1.25586502e-02],\n",
       "       [9.32925522e-01, 6.70744181e-02],\n",
       "       [5.54615855e-01, 4.45384145e-01],\n",
       "       [9.97266531e-01, 2.73353700e-03],\n",
       "       [9.97016668e-01, 2.98329676e-03],\n",
       "       [9.81996536e-01, 1.80035271e-02],\n",
       "       [6.70334458e-01, 3.29665571e-01],\n",
       "       [5.49910903e-01, 4.50089037e-01],\n",
       "       [9.99996901e-01, 3.13931423e-06],\n",
       "       [7.75791287e-01, 2.24208683e-01],\n",
       "       [3.18100423e-01, 6.81899607e-01],\n",
       "       [1.05535805e-01, 8.94464195e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reloaded=load_model('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('Dataset/Test/infected/2.png',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reloaded.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(model_reloaded.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infected\n"
     ]
    }
   ],
   "source": [
    "if(a==1):\n",
    "    print(\"Uninfected\")\n",
    "else:\n",
    "    print(\"Infected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
